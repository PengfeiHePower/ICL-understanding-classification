{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed6cfeb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "import re\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from eval import get_run_metrics, read_run_dir, get_model_from_run\n",
    "from plot_utils import basic_plot, collect_results, relevant_model_names\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "sns.set_theme('notebook', 'darkgrid')\n",
    "palette = sns.color_palette('colorblind')\n",
    "\n",
    "run_dir = \"../models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e8d018b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>task</th>\n",
       "      <th>model</th>\n",
       "      <th>kwargs</th>\n",
       "      <th>num_tasks</th>\n",
       "      <th>num_examples</th>\n",
       "      <th>n_dims</th>\n",
       "      <th>n_layer</th>\n",
       "      <th>n_head</th>\n",
       "      <th>run_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pretrained</td>\n",
       "      <td>decision_tree</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>depth=4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>decision_tree_pretrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pretrained</td>\n",
       "      <td>linear_classification</td>\n",
       "      <td>Transformer</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>linear_classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pretrained</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>Transformer</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>linear_regression_pretrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pretrained</td>\n",
       "      <td>relu_2nn_regression</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>hidden_layer_size=100</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>relu_2nn_regression_pretrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pretrained</td>\n",
       "      <td>sparse_linear_regression</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>sparsity=3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>sparse_regression_pretrained</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       run_id                      task        model                 kwargs  \\\n",
       "3  pretrained             decision_tree  Transformer                depth=4   \n",
       "4  pretrained     linear_classification  Transformer                          \n",
       "1  pretrained         linear_regression  Transformer                          \n",
       "0  pretrained       relu_2nn_regression  Transformer  hidden_layer_size=100   \n",
       "2  pretrained  sparse_linear_regression  Transformer             sparsity=3   \n",
       "\n",
       "   num_tasks  num_examples  n_dims  n_layer  n_head  \\\n",
       "3         -1            -1      20       12       8   \n",
       "4         -1            -1      20       12       8   \n",
       "1         -1            -1      20       12       8   \n",
       "0         -1            -1      20       12       8   \n",
       "2         -1            -1      20       12       8   \n",
       "\n",
       "                         run_name  \n",
       "3        decision_tree_pretrained  \n",
       "4           linear_classification  \n",
       "1    linear_regression_pretrained  \n",
       "0  relu_2nn_regression_pretrained  \n",
       "2    sparse_regression_pretrained  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_run_dir(run_dir)\n",
    "df  # list all the runs in our run_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9980951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task = \"linear_regression\"\n",
    "#task = \"sparse_linear_regression\"\n",
    "#task = \"decision_tree\"\n",
    "#task = \"relu_2nn_regression\"\n",
    "task = \"linear_classification\"\n",
    "\n",
    "run_id = \"pretrained\"  # if you train more models, replace with the run_id from the table above\n",
    "\n",
    "run_path = os.path.join(run_dir, task, run_id)\n",
    "recompute_metrics = False\n",
    "\n",
    "if recompute_metrics:\n",
    "    get_run_metrics(run_path)  # these are normally precomputed at the end of training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d09964",
   "metadata": {},
   "source": [
    "# Plot pre-computed metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd8e02c5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear_classification pretrained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 15650.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def valid_row(r):\n",
    "    return r.task == task and r.run_id == run_id\n",
    "\n",
    "metrics = collect_results(run_dir, df, valid_row=valid_row)\n",
    "_, conf = get_model_from_run(run_path, only_conf=True)\n",
    "n_dims = conf.model.n_dims\n",
    "\n",
    "models = relevant_model_names[task]\n",
    "basic_plot(metrics[\"standard\"], models=models)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "31b4ecca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot any OOD metrics\n",
    "for name, metric in metrics.items():\n",
    "    if name == \"standard\": continue\n",
    "   \n",
    "    if \"scale\" in name:\n",
    "        scale = float(name.split(\"=\")[-1])**2\n",
    "    else:\n",
    "        scale = 1.0\n",
    "\n",
    "    trivial = 1.0 if \"noisy\" not in name else (1+1/n_dims)\n",
    "    fig, ax = basic_plot(metric, models=models, trivial=trivial * scale)\n",
    "    ax.set_title(name)\n",
    "    \n",
    "    if \"ortho\" in name:\n",
    "        ax.set_xlim(-1, n_dims - 1)\n",
    "    ax.set_ylim(-.1 * scale, 1.5 * scale)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f961d4",
   "metadata": {},
   "source": [
    "# Interactive setup\n",
    "\n",
    "We will now directly load the model and measure its in-context learning ability on a batch of random inputs. (In the paper we average over multiple such batches to obtain better estimates.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beb327ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from samplers import get_data_sampler\n",
    "from tasks import get_task_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03523b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, conf = get_model_from_run(run_path)\n",
    "\n",
    "n_dims = conf.model.n_dims\n",
    "batch_size = conf.training.batch_size\n",
    "\n",
    "# data_sampler = get_data_sampler(conf.training.data, n_dims)\n",
    "task_sampler = get_task_sampler(\n",
    "    conf.training.task,\n",
    "    n_dims,\n",
    "    batch_size,\n",
    "    **conf.training.task_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07615e2b",
   "metadata": {},
   "source": [
    "### Inference data generation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce368f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_within_batch(xs, ys):\n",
    "    b_size, n_points, _ = xs.shape\n",
    "    # Generate a random permutation for each batch\n",
    "    permutations = torch.randperm(n_points).repeat(b_size, 1)\n",
    "\n",
    "    # Apply the same permutation to each batch in xs and ys\n",
    "    xs_shuffled = torch.gather(xs, 1, permutations.unsqueeze(-1).expand(-1, -1, xs.size(2)))\n",
    "    ys_shuffled = torch.gather(ys, 1, permutations)\n",
    "\n",
    "    return xs_shuffled, ys_shuffled\n",
    "\n",
    "## generate inference data\n",
    "def testSample(n_points, b_size, bias1=1, bias2=-1, std=2.0, p1=0.7,p2=0.7,frac_pos=0.5):\n",
    "    x_bias1 = torch.normal(mean=bias1, std=std, size=(1, n_dims))\n",
    "    x_bias2 = torch.normal(mean=bias2, std=std, size=(1, n_dims))\n",
    "    split_index = int(n_points * frac_pos)\n",
    "    if n_points>0:\n",
    "        ## first obtain in-context examples\n",
    "        xs_b = torch.randn(b_size, n_points, n_dims)\n",
    "        xs_b[:, :split_index, :] += x_bias1\n",
    "        xs_b[:, split_index:, :] += x_bias2\n",
    "        \n",
    "        true_y = torch.empty(b_size, n_points)\n",
    "        probs_first_half = torch.tensor([p1, 1-p1])  # Probability for 1 and -1 respectively\n",
    "        choices_first_half = torch.tensor([1, -1])\n",
    "        if split_index>0:\n",
    "            first_half = torch.multinomial(probs_first_half, b_size * split_index, replacement=True).reshape(b_size, split_index)\n",
    "            true_y[:, :split_index] = choices_first_half[first_half]\n",
    "        probs_second_half = torch.tensor([1-p2, p2])  # Probability for 1 and -1 respectively\n",
    "        choices_second_half = torch.tensor([1, -1])\n",
    "        if n_points - split_index>0:\n",
    "            second_half = torch.multinomial(probs_second_half, b_size * (n_points - split_index), replacement=True).reshape(b_size, n_points - split_index)\n",
    "            true_y[:, split_index:] = choices_second_half[second_half]\n",
    "        #shuffle examples\n",
    "        xs_b, true_y = shuffle_within_batch(xs_b, true_y)\n",
    "        \n",
    "        ## add query samples\n",
    "        split_batch = b_size // 2\n",
    "        additional_first_half = torch.randn(split_batch, 1, n_dims) \n",
    "        additional_first_half += x_bias1\n",
    "        additional_second_half = torch.randn(b_size - split_batch, 1, n_dims) \n",
    "        additional_second_half += x_bias2\n",
    "        additional_points = torch.cat([additional_first_half, additional_second_half], dim=0)\n",
    "        xs_b = torch.cat([xs_b, additional_points], dim=1)\n",
    "        \n",
    "        additional_first_half = torch.ones((split_batch, 1))\n",
    "        additional_second_half = -torch.ones((b_size - split_batch, 1))\n",
    "        additional_labels = torch.cat([additional_first_half, additional_second_half], dim=0)\n",
    "        true_y = torch.cat([true_y, additional_labels], dim=1)\n",
    "    \n",
    "    else:\n",
    "        #zero-shot, only query samples\n",
    "        split_batch = b_size // 2\n",
    "        additional_first_half = torch.randn(split_batch, 1, n_dims) \n",
    "        additional_first_half += x_bias1\n",
    "        additional_second_half = torch.randn(b_size - split_batch, 1, n_dims) \n",
    "        additional_second_half += x_bias2\n",
    "        xs_b = torch.cat([additional_first_half, additional_second_half], dim=0)\n",
    "        additional_first_half = torch.ones((split_batch, 1))\n",
    "        additional_second_half = -torch.ones((b_size - split_batch, 1))\n",
    "        true_y = torch.cat([additional_first_half, additional_second_half], dim=0)\n",
    "    \n",
    "    return xs_b, true_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d9da7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = task_sampler()\n",
    "# xs = data_sampler.sample_xs(b_size=batch_size, n_points=conf.training.curriculum.points.end)\n",
    "# ys = task.generate_true_y(xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dd0977",
   "metadata": {},
   "source": [
    "#### Inference function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d096cecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testF(n_points, b_size, bias1, bias2, std, p1, p2, frac_pos, model, rep=100):\n",
    "    pos_pos_ls = []\n",
    "    neg_neg_ls = []\n",
    "    \n",
    "    for _ in range(rep):\n",
    "        xs, ys = testSample(n_points, b_size, bias1, bias2, std, p1, p2, frac_pos)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pred = model(xs, ys).sign()\n",
    "\n",
    "        pred_pos = pred[:b_size//2,-1]\n",
    "        pred_neg = pred[b_size//2:,-1]\n",
    "\n",
    "        pos_pos = sum(pred_pos==1)/len(pred_pos)\n",
    "        neg_neg = sum(pred_neg==-1)/len(pred_neg)\n",
    "        \n",
    "        pos_pos_ls.append(pos_pos)\n",
    "        neg_neg_ls.append(neg_neg)\n",
    "    \n",
    "    pos_pos_np = np.array(pos_pos_ls)\n",
    "    neg_neg_np = np.array(neg_neg_ls)\n",
    "    \n",
    "    pos_pos_avg = np.mean(pos_pos_np)\n",
    "    neg_neg_avg = np.mean(neg_neg_np)\n",
    "    \n",
    "    pos_pos_std = np.std(pos_pos_np, ddof=1)\n",
    "    neg_neg_std = np.std(neg_neg_np, ddof=1)\n",
    "    \n",
    "    return [pos_pos_avg, neg_neg_avg], [pos_pos_std, neg_neg_std]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0c605d",
   "metadata": {},
   "source": [
    "### Zero-shot prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2686ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.118]\n",
      "[0.0, 0.15839192]\n"
     ]
    }
   ],
   "source": [
    "n_points=0\n",
    "b_size = 1000\n",
    "bias1=0.5\n",
    "bias2=-0.5\n",
    "std=1.0\n",
    "p1=1.0\n",
    "p2=1.0\n",
    "frac_pos=1.0\n",
    "# xs, ys = testSample(n_points, b_size, bias1, bias2, std, p1, p2, frac_pos)\n",
    "\n",
    "\n",
    "dist, sd = testF(n_points, b_size, bias1, bias2, std, p1, p2, frac_pos, model, rep=100)\n",
    "print(dist)\n",
    "print(sd)\n",
    "# with torch.no_grad():\n",
    "#     pred = model(xs, ys).sign()\n",
    "\n",
    "# pred_pos = pred[:b_size//2,-1]\n",
    "# pred_neg = pred[b_size//2:,-1]\n",
    "\n",
    "# pos_pos = sum(pred_pos==1)/len(pred_pos)\n",
    "# neg_neg = sum(pred_neg==-1)/len(pred_neg)\n",
    "\n",
    "# print(f\"pos_pos:{pos_pos}\")\n",
    "# print(f\"neg_neg:{neg_neg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fca768",
   "metadata": {},
   "source": [
    "### Few-shot prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "74f163f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m xs, ys \u001b[38;5;241m=\u001b[39m testSample(n_points, b_size, bias1, bias2, std, p1, p2, frac_pos)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 12\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mys\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msign()\n\u001b[1;32m     14\u001b[0m pred_pos \u001b[38;5;241m=\u001b[39m pred[:b_size\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     15\u001b[0m pred_neg \u001b[38;5;241m=\u001b[39m pred[b_size\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/icl/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/in-context-learning/src/models.py:125\u001b[0m, in \u001b[0;36mTransformerModel.forward\u001b[0;34m(self, xs, ys, inds)\u001b[0m\n\u001b[1;32m    123\u001b[0m zs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine(xs, ys)\n\u001b[1;32m    124\u001b[0m embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_in(zs)\n\u001b[0;32m--> 125\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeds\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[1;32m    126\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_out(output)\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prediction[:, ::\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m][:, inds]\n",
      "File \u001b[0;32m~/anaconda3/envs/icl/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/icl/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py:834\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    833\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwte(input_ids)\n\u001b[0;32m--> 834\u001b[0m position_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwpe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m position_embeds\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m token_type_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/icl/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/icl/lib/python3.8/site-packages/torch/nn/modules/sparse.py:158\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/icl/lib/python3.8/site-packages/torch/nn/functional.py:2183\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2177\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2178\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2179\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2180\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2181\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2182\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "b_size = 1000\n",
    "n_points= 100\n",
    "bias1 = 0.5\n",
    "bias2 = -0.5\n",
    "std = 2.0\n",
    "p1 = 1.0\n",
    "p2 = 1.0\n",
    "frac_pos = 1.0\n",
    "xs, ys = testSample(n_points, b_size, bias1, bias2, std, p1, p2, frac_pos)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = model(xs, ys).sign()\n",
    "\n",
    "pred_pos = pred[:b_size//2,-1]\n",
    "pred_neg = pred[b_size//2:,-1]\n",
    "\n",
    "pos_pos = sum(pred_pos==1)/len(pred_pos)\n",
    "neg_neg = sum(pred_neg==-1)/len(pred_neg)\n",
    "\n",
    "print(f\"pos_pos:{pos_pos}\")\n",
    "print(f\"neg_neg:{neg_neg}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
